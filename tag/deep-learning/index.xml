<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning | Academic website</title>
    <link>https://zhengleily.github.io/tag/deep-learning/</link>
      <atom:link href="https://zhengleily.github.io/tag/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Deep Learning</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 27 Apr 2016 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://zhengleily.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Deep Learning</title>
      <link>https://zhengleily.github.io/tag/deep-learning/</link>
    </image>
    
    <item>
      <title>Example Project</title>
      <link>https://zhengleily.github.io/project/example/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://zhengleily.github.io/project/example/</guid>
      <description>&lt;p&gt;This on-going project aims to develop autonomous car-following strategies based on deep Reinforcement Learning (deep RL).&lt;/p&gt;
&lt;p&gt;Deep Reinforcement Learning
Deep RL is a field that seeks to combine the advances in deep neural networks with reinforcement learning algorithms to create agents capable of acting intelligently in complex environments, and exciting breakthroughs have been witnessed, like deep Q-network and AlphaGo.&lt;/p&gt;
&lt;p&gt;Deep reinforcement learning can achieve better generalization capability because it learns decision-making mechanisms from training data rather than parameter estimation through fitting the data.&lt;/p&gt;
&lt;p&gt;Autonomous Car Following
The critical element in developing autonomous car-following strategies by reinforcement learning is the design of the reward function. Currently, we have developed two types of reward functions: 1) reward function reflecting deviations from human driving performance, leading to human-like car following; and 2) reward function reflecting driving efficiency, safety, and comfort, leading to multi-objective autonomous car-following.&lt;/p&gt;
&lt;p&gt;The following demo animation shows the car-following learning process of RL agents. In early training episodes, cars become red frequently, indicating penalties caused by bad car-following performance, e.g., rear-end crashes. As training converges, the RL agents maintain steady car-following headways, and receive fewer penalties.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
